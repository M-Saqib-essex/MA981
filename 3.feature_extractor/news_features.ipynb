{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extracting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning data path\n",
    "df = pd.read_csv('../2.data_preprocessing/pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Title</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>As he traveled the country on his thank you to...</td>\n",
       "      <td>Donald Trumps Cabinet richest in US history hi...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>A federal judge in New York has unsealed the s...</td>\n",
       "      <td>Judge unseals warrant for search of Anthony We...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>On Sunday evening Donald Trump invited reporte...</td>\n",
       "      <td>Donald Trump invites press to offtherecord ses...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>WASHINGTON  Allegations of retaliation against...</td>\n",
       "      <td>NSA watchdog put on leave in whistleblower case</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>A group of millennial activists from across th...</td>\n",
       "      <td>Trump protesters plan to open movement house i...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  News  \\\n",
       "246  As he traveled the country on his thank you to...   \n",
       "247  A federal judge in New York has unsealed the s...   \n",
       "248  On Sunday evening Donald Trump invited reporte...   \n",
       "249  WASHINGTON  Allegations of retaliation against...   \n",
       "250  A group of millennial activists from across th...   \n",
       "\n",
       "                                                 Title Label  \n",
       "246  Donald Trumps Cabinet richest in US history hi...  Real  \n",
       "247  Judge unseals warrant for search of Anthony We...  Real  \n",
       "248  Donald Trump invites press to offtherecord ses...  Real  \n",
       "249    NSA watchdog put on leave in whistleblower case  Real  \n",
       "250  Trump protesters plan to open movement house i...  Real  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking end of dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char count\n",
    "#word count\n",
    "#title word count\n",
    "#stop word count\n",
    "#upper case word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char count\n",
    "df['char_count'] = df['News'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count\n",
    "df['word_count'] = df['News'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title word count\n",
    "df['title_word_count'] = df['Title'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword count\n",
    "from nltk.corpus import stopwords    \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['stopword_count'] = df['News'].str.split().apply(lambda x: len(set(x) & stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper case word count\n",
    "df['upper_case'] = df['News'].str.count(r'[A-Z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Title</th>\n",
       "      <th>Label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>upper_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Internet is buzzing today after white supr...</td>\n",
       "      <td>Million Uncounted Sanders Ballots Found On Cl...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1169</td>\n",
       "      <td>223</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUMP TOWER — With his poll numbers among blac...</td>\n",
       "      <td>African Billionaire Will Give  Million To Anyo...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>2291</td>\n",
       "      <td>376</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is looking to assemble a strong t...</td>\n",
       "      <td>BREAKING Another Clinton Associate Set To Test...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1381</td>\n",
       "      <td>247</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“SHE’S SEXY SMART SOPHISTICATED AND SHE’S INTO...</td>\n",
       "      <td>Breaking Fraudulent Clinton Votes Discovered B...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>503</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHOENIX AZ AP — For months now rumors have cir...</td>\n",
       "      <td>BREAKING Official Set to Testify Against Hilla...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>7381</td>\n",
       "      <td>1317</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  \\\n",
       "0  The Internet is buzzing today after white supr...   \n",
       "1  TRUMP TOWER — With his poll numbers among blac...   \n",
       "2  Donald Trump is looking to assemble a strong t...   \n",
       "3  “SHE’S SEXY SMART SOPHISTICATED AND SHE’S INTO...   \n",
       "4  PHOENIX AZ AP — For months now rumors have cir...   \n",
       "\n",
       "                                               Title Label  char_count  \\\n",
       "0   Million Uncounted Sanders Ballots Found On Cl...  Fake        1169   \n",
       "1  African Billionaire Will Give  Million To Anyo...  Fake        2291   \n",
       "2  BREAKING Another Clinton Associate Set To Test...  Fake        1381   \n",
       "3  Breaking Fraudulent Clinton Votes Discovered B...  Fake         503   \n",
       "4  BREAKING Official Set to Testify Against Hilla...  Fake        7381   \n",
       "\n",
       "   word_count  title_word_count  stopword_count  upper_case  \n",
       "0         223                 9              38          37  \n",
       "1         376                18              57         146  \n",
       "2         247                11              34          68  \n",
       "3          93                 9              23         144  \n",
       "4        1317                 9              86         221  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polarity \n",
    "#subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "  \n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "  \n",
    "#Create two new columns ‘Subjectivity’ & ‘Polarity’\n",
    "df['subjectivity'] = df['News'].apply(getSubjectivity)\n",
    "df['polarity'] = df['News'].apply(getPolarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Title</th>\n",
       "      <th>Label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>upper_case</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Internet is buzzing today after white supr...</td>\n",
       "      <td>Million Uncounted Sanders Ballots Found On Cl...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1169</td>\n",
       "      <td>223</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>-0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUMP TOWER — With his poll numbers among blac...</td>\n",
       "      <td>African Billionaire Will Give  Million To Anyo...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>2291</td>\n",
       "      <td>376</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>146</td>\n",
       "      <td>0.462568</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is looking to assemble a strong t...</td>\n",
       "      <td>BREAKING Another Clinton Associate Set To Test...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1381</td>\n",
       "      <td>247</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>68</td>\n",
       "      <td>0.558531</td>\n",
       "      <td>0.111726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“SHE’S SEXY SMART SOPHISTICATED AND SHE’S INTO...</td>\n",
       "      <td>Breaking Fraudulent Clinton Votes Discovered B...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>503</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.283036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHOENIX AZ AP — For months now rumors have cir...</td>\n",
       "      <td>BREAKING Official Set to Testify Against Hilla...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>7381</td>\n",
       "      <td>1317</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>221</td>\n",
       "      <td>0.434617</td>\n",
       "      <td>0.126710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  \\\n",
       "0  The Internet is buzzing today after white supr...   \n",
       "1  TRUMP TOWER — With his poll numbers among blac...   \n",
       "2  Donald Trump is looking to assemble a strong t...   \n",
       "3  “SHE’S SEXY SMART SOPHISTICATED AND SHE’S INTO...   \n",
       "4  PHOENIX AZ AP — For months now rumors have cir...   \n",
       "\n",
       "                                               Title Label  char_count  \\\n",
       "0   Million Uncounted Sanders Ballots Found On Cl...  Fake        1169   \n",
       "1  African Billionaire Will Give  Million To Anyo...  Fake        2291   \n",
       "2  BREAKING Another Clinton Associate Set To Test...  Fake        1381   \n",
       "3  Breaking Fraudulent Clinton Votes Discovered B...  Fake         503   \n",
       "4  BREAKING Official Set to Testify Against Hilla...  Fake        7381   \n",
       "\n",
       "   word_count  title_word_count  stopword_count  upper_case  subjectivity  \\\n",
       "0         223                 9              38          37      0.262500   \n",
       "1         376                18              57         146      0.462568   \n",
       "2         247                11              34          68      0.558531   \n",
       "3          93                 9              23         144      0.476190   \n",
       "4        1317                 9              86         221      0.434617   \n",
       "\n",
       "   polarity  \n",
       "0 -0.025000  \n",
       "1  0.110800  \n",
       "2  0.111726  \n",
       "3  0.283036  \n",
       "4  0.126710  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count noun\n",
    "# count verb\n",
    "# count adjective\n",
    "# count pronoun\n",
    "# count adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convering news column to list\n",
    "texts = df['News'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying pos tagger\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving in a column\n",
    "df['POS'] = tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NounCounter(x):\n",
    "    nouns = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"NN\"):\n",
    "            nouns.append(word)\n",
    "    return nouns\n",
    "\n",
    "def CounjuctionCounter(x):\n",
    "    counjuctions = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"IN\"):\n",
    "            counjuctions.append(word)\n",
    "    return counjuctions\n",
    "\n",
    "def AdjectiveCounter(x):\n",
    "    adjectives = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"JJ\"):\n",
    "            adjectives.append(word)\n",
    "    return adjectives\n",
    "\n",
    "def ProNounCounter(x):\n",
    "    pronouns = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"PRP\"):\n",
    "            pronouns.append(word)\n",
    "    return pronouns\n",
    "\n",
    "def AdverbCounter(x):\n",
    "    adverb = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"RB\"):\n",
    "            adverb.append(word)\n",
    "    return adverb\n",
    "\n",
    "def PrepositionCounter(x):\n",
    "    prep = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"TO\"):\n",
    "            prep.append(word)\n",
    "    return prep\n",
    "\n",
    "def InterjectionCounter(x):\n",
    "    inter = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"UH\"):\n",
    "            inter.append(word)\n",
    "    return inter\n",
    "\n",
    "def VerbCounter(x):\n",
    "    verbs = []\n",
    "    for (word, pos) in x:\n",
    "        if pos.startswith(\"VB\"):\n",
    "            verbs.append(word)\n",
    "    return verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding nouns and noun count\n",
    "df[\"nouns\"] = df[\"POS\"].apply(NounCounter)\n",
    "df[\"noun_count\"] = df[\"nouns\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding conjunction and conjunction count\n",
    "df[\"conjuctions\"] = df[\"POS\"].apply(CounjuctionCounter)\n",
    "df[\"conjuction_count\"] = df[\"conjuctions\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding adjective and adjective count\n",
    "df[\"adjectives\"] = df[\"POS\"].apply(AdjectiveCounter)\n",
    "df[\"adjective_count\"] = df[\"adjectives\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding pronouns and pronoun count\n",
    "df[\"pronouns\"] = df[\"POS\"].apply(ProNounCounter)\n",
    "df[\"pronoun_count\"] = df[\"pronouns\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding adverbs and adverb count\n",
    "df[\"adverbs\"] = df[\"POS\"].apply(AdverbCounter)\n",
    "df[\"adverb_count\"] = df[\"adverbs\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding prepositions and preposition count\n",
    "df[\"prepositions\"] = df[\"POS\"].apply(PrepositionCounter)\n",
    "df[\"prepositions_count\"] = df[\"prepositions\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding interjections and interjection count\n",
    "df[\"interjections\"] = df[\"POS\"].apply(InterjectionCounter)\n",
    "df[\"interjection_count\"] = df[\"interjections\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding verbs and verbs count\n",
    "df[\"verbs\"] = df[\"POS\"].apply(VerbCounter)\n",
    "df[\"verb_count\"] = df[\"verbs\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Title</th>\n",
       "      <th>Label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>upper_case</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>...</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>prepositions</th>\n",
       "      <th>prepositions_count</th>\n",
       "      <th>interjections</th>\n",
       "      <th>interjection_count</th>\n",
       "      <th>verbs</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Internet is buzzing today after white supr...</td>\n",
       "      <td>Million Uncounted Sanders Ballots Found On Cl...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1169</td>\n",
       "      <td>223</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>[his, it, I, I, I, it, it, his, he, I, him, he...</td>\n",
       "      <td>32</td>\n",
       "      <td>[maybe, back, not, not, So, now]</td>\n",
       "      <td>6</td>\n",
       "      <td>[to, to, na, to, to, to, to, to, to]</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[is, buzzing, was, caught, snorting, brought, ...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUMP TOWER — With his poll numbers among blac...</td>\n",
       "      <td>African Billionaire Will Give  Million To Anyo...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>2291</td>\n",
       "      <td>376</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>146</td>\n",
       "      <td>0.462568</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>...</td>\n",
       "      <td>[his, his, She, she, you, her, She, we, her, W...</td>\n",
       "      <td>37</td>\n",
       "      <td>[around, reportedly, ll, recently, now, more, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>[to, to, to, to, to, to, To, to, to]</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[hovering, tapped, connects, said, ’, be, see,...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is looking to assemble a strong t...</td>\n",
       "      <td>BREAKING Another Clinton Associate Set To Test...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1381</td>\n",
       "      <td>247</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>68</td>\n",
       "      <td>0.558531</td>\n",
       "      <td>0.111726</td>\n",
       "      <td>...</td>\n",
       "      <td>[he, he, his, His, His, it, he, I, We, I, he, ...</td>\n",
       "      <td>32</td>\n",
       "      <td>[earlier, not, thus, far, already]</td>\n",
       "      <td>5</td>\n",
       "      <td>[to, to, to, to, to]</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[is, looking, assemble, enters, expected, cons...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“SHE’S SEXY SMART SOPHISTICATED AND SHE’S INTO...</td>\n",
       "      <td>Breaking Fraudulent Clinton Votes Discovered B...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>503</td>\n",
       "      <td>93</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.283036</td>\n",
       "      <td>...</td>\n",
       "      <td>[his, her, you, it]</td>\n",
       "      <td>4</td>\n",
       "      <td>[not]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[ARE, choosing, running, did, vote, comes, was...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHOENIX AZ AP — For months now rumors have cir...</td>\n",
       "      <td>BREAKING Official Set to Testify Against Hilla...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>7381</td>\n",
       "      <td>1317</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>221</td>\n",
       "      <td>0.434617</td>\n",
       "      <td>0.126710</td>\n",
       "      <td>...</td>\n",
       "      <td>[he, I, I, I, them, me, my, I, I, I, they, me,...</td>\n",
       "      <td>143</td>\n",
       "      <td>[now, rally, back, forward, rally, “, mostly, ...</td>\n",
       "      <td>56</td>\n",
       "      <td>[to, to, to, to, to, to, to, to, to, to, to, t...</td>\n",
       "      <td>35</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[have, circulated, were, being, paid, protest,...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  \\\n",
       "0  The Internet is buzzing today after white supr...   \n",
       "1  TRUMP TOWER — With his poll numbers among blac...   \n",
       "2  Donald Trump is looking to assemble a strong t...   \n",
       "3  “SHE’S SEXY SMART SOPHISTICATED AND SHE’S INTO...   \n",
       "4  PHOENIX AZ AP — For months now rumors have cir...   \n",
       "\n",
       "                                               Title Label  char_count  \\\n",
       "0   Million Uncounted Sanders Ballots Found On Cl...  Fake        1169   \n",
       "1  African Billionaire Will Give  Million To Anyo...  Fake        2291   \n",
       "2  BREAKING Another Clinton Associate Set To Test...  Fake        1381   \n",
       "3  Breaking Fraudulent Clinton Votes Discovered B...  Fake         503   \n",
       "4  BREAKING Official Set to Testify Against Hilla...  Fake        7381   \n",
       "\n",
       "   word_count  title_word_count  stopword_count  upper_case  subjectivity  \\\n",
       "0         223                 9              38          37      0.262500   \n",
       "1         376                18              57         146      0.462568   \n",
       "2         247                11              34          68      0.558531   \n",
       "3          93                 9              23         144      0.476190   \n",
       "4        1317                 9              86         221      0.434617   \n",
       "\n",
       "   polarity  ...                                           pronouns  \\\n",
       "0 -0.025000  ...  [his, it, I, I, I, it, it, his, he, I, him, he...   \n",
       "1  0.110800  ...  [his, his, She, she, you, her, She, we, her, W...   \n",
       "2  0.111726  ...  [he, he, his, His, His, it, he, I, We, I, he, ...   \n",
       "3  0.283036  ...                                [his, her, you, it]   \n",
       "4  0.126710  ...  [he, I, I, I, them, me, my, I, I, I, they, me,...   \n",
       "\n",
       "  pronoun_count                                            adverbs  \\\n",
       "0            32                   [maybe, back, not, not, So, now]   \n",
       "1            37  [around, reportedly, ll, recently, now, more, ...   \n",
       "2            32                 [earlier, not, thus, far, already]   \n",
       "3             4                                              [not]   \n",
       "4           143  [now, rally, back, forward, rally, “, mostly, ...   \n",
       "\n",
       "  adverb_count                                       prepositions  \\\n",
       "0            6               [to, to, na, to, to, to, to, to, to]   \n",
       "1           22               [to, to, to, to, to, to, To, to, to]   \n",
       "2            5                               [to, to, to, to, to]   \n",
       "3            1                                                 []   \n",
       "4           56  [to, to, to, to, to, to, to, to, to, to, to, t...   \n",
       "\n",
       "  prepositions_count  interjections interjection_count  \\\n",
       "0                  9             []                  0   \n",
       "1                  9             []                  0   \n",
       "2                  5             []                  0   \n",
       "3                  0             []                  0   \n",
       "4                 35             []                  0   \n",
       "\n",
       "                                               verbs verb_count  \n",
       "0  [is, buzzing, was, caught, snorting, brought, ...         54  \n",
       "1  [hovering, tapped, connects, said, ’, be, see,...         91  \n",
       "2  [is, looking, assemble, enters, expected, cons...         62  \n",
       "3  [ARE, choosing, running, did, vote, comes, was...         11  \n",
       "4  [have, circulated, were, being, paid, protest,...        299  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['News', 'Title', 'Label', 'char_count', 'word_count',\n",
       "       'title_word_count', 'stopword_count', 'upper_case', 'subjectivity',\n",
       "       'polarity', 'POS', 'nouns', 'noun_count', 'conjuctions',\n",
       "       'conjuction_count', 'adjectives', 'adjective_count', 'pronouns',\n",
       "       'pronoun_count', 'adverbs', 'adverb_count', 'prepositions',\n",
       "       'prepositions_count', 'interjections', 'interjection_count', 'verbs',\n",
       "       'verb_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving dataframe to csv file\n",
    "df.to_csv('feature_extractor.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
